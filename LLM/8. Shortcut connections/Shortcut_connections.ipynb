{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO/4GesxkKJ2azbWE+CIf7P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RCortez25/PhD/blob/main/LLM/8.%20Shortcut%20connections/Shortcut_connections.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Shortcut connections\n",
        "\n",
        "Shortcut connections were introduced to solve the problem of vanishing gradients, in which gradients become smaller and smaller as they propagate backward so it's difficult to train earlier layers.\n",
        "\n",
        "These connections create an alternative path for the gradient to flow by skipping one or more layers. This is achieved by adding the output of one layer to the output of a latter layer.\n",
        "\n",
        "Let's create a NN to see the effect of shortcut connections."
      ],
      "metadata": {
        "id": "sOyBMQWK5rmb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class GELU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        result = 0.5 * x * (1 + torch.tanh(\n",
        "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
        "            (x + 0.044715 * torch.pow(x, 3))\n",
        "        ))\n",
        "        return result"
      ],
      "metadata": {
        "id": "ddR0YqJ1_UDp"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Rckh1R355R7r"
      },
      "outputs": [],
      "source": [
        "class ExampleDeepNeuralNetwork(nn.Module):\n",
        "    def __init__(self, layer_sizes, use_shortcut):\n",
        "        super().__init__()\n",
        "        self.use_shortcut = use_shortcut\n",
        "        self.layers = nn.ModuleList([\n",
        "                nn.Sequential(\n",
        "                    nn.Linear(layer_sizes[i], layer_sizes[i + 1]),\n",
        "                    GELU())\n",
        "            for i in range(len(layer_sizes) - 1)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            # Compute the output of the current layer\n",
        "            output = layer(x)\n",
        "            # Check if shortcut can be applied\n",
        "            if self.use_shortcut and x.shape == output.shape:\n",
        "                # Apply shortcut\n",
        "                x = x + output\n",
        "            else:\n",
        "                x = output\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example"
      ],
      "metadata": {
        "id": "e1mH0DqYBP4B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the layers. 6 layers, the first 5 with 3 neurons each and the last one\n",
        "# with 1 neuron\n",
        "layer_sizes = [3, 3, 3, 3, 3, 1]\n",
        "inputs = torch.tensor([[1., 0., -1.]])\n",
        "torch.manual_seed(123)\n",
        "network_without_shortcut = ExampleDeepNeuralNetwork(layer_sizes, use_shortcut=False)"
      ],
      "metadata": {
        "id": "PSUlTBqxBQkk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate the gradients\n",
        "def print_gradients(model, x):\n",
        "    # Forward pass\n",
        "    output = model(x)\n",
        "    target = torch.tensor([[0.]])\n",
        "\n",
        "    # Calculate the loss based on how close we are to the target\n",
        "    loss = nn.MSELoss()\n",
        "    loss = loss(output, target)\n",
        "\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "\n",
        "    for name, param in model.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            # Print the mean absolute gradient of the weights\n",
        "            print(f\"Mean absolute gradient of {name}: {torch.mean(torch.abs(param.grad))}\")"
      ],
      "metadata": {
        "id": "-OVSorRj_wAf"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the example\n",
        "print_gradients(network_without_shortcut, inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQ4Fflw3Fjeo",
        "outputId": "ee4302b1-75af-46ee-e709-70c488c0d432"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean absolute gradient of layers.0.0.weight: 0.00020173584925942123\n",
            "Mean absolute gradient of layers.1.0.weight: 0.00012011159560643137\n",
            "Mean absolute gradient of layers.2.0.weight: 0.0007152040489017963\n",
            "Mean absolute gradient of layers.3.0.weight: 0.0013988736318424344\n",
            "Mean absolute gradient of layers.4.0.weight: 0.005049645435065031\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As can be seen, when one moves from layer 4 to layer 0 the gradients become smaller and smaller.\n",
        "\n",
        "Now, let's repeat the same example with shortcut connections."
      ],
      "metadata": {
        "id": "69qsJFA6FvwV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "network_with_shortcut = ExampleDeepNeuralNetwork(layer_sizes, use_shortcut=True)\n",
        "print_gradients(network_with_shortcut, inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkxxzVWdFmpP",
        "outputId": "5962c87a-6765-4cf5-f7b0-7ef85168b3f7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean absolute gradient of layers.0.0.weight: 0.22169791162014008\n",
            "Mean absolute gradient of layers.1.0.weight: 0.20694105327129364\n",
            "Mean absolute gradient of layers.2.0.weight: 0.32896995544433594\n",
            "Mean absolute gradient of layers.3.0.weight: 0.2665732204914093\n",
            "Mean absolute gradient of layers.4.0.weight: 1.3258540630340576\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The difference can clearly be seen."
      ],
      "metadata": {
        "id": "ZQjrEv2_GLqf"
      }
    }
  ]
}